{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import sys, time, datetime, shutil, os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "import csv\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "BATCH_SIZE = 32\n",
    "NB_EPOCHS = 100\n",
    "IMG_WIDTH = 96\n",
    "IMG_HEIGHT = 96\n",
    "TRAIN_DATA_PATH = 'chest_xray/train'\n",
    "TEST_DATA_PATH = 'chest_xray/test'\n",
    "VAL_DATA_PATH = 'chest_xray/val'\n",
    "CLASS_NAMES = ['NORMAL', 'BACTERIA', 'VIRUS']\n",
    "NUM_CLASSES = 3\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = 'adam'\n",
    "HIDDEN_ACTIVATION = 'relu'\n",
    "FINAL_ACTIVATION = 'sigmoid'\n",
    "\n",
    "METRICS = [\n",
    "  tf.keras.metrics.CategoricalAccuracy(name='accuracy', dtype=tf.float32),\n",
    "  tf.keras.metrics.TruePositives(name='true_positives', dtype=tf.float32),\n",
    "  tf.keras.metrics.FalsePositives(name='false_positives', dtype=tf.float32),\n",
    "  tf.keras.metrics.TrueNegatives(name='true_negatives', dtype=tf.float32),\n",
    "  tf.keras.metrics.FalseNegatives(name='false_negatives', dtype=tf.float32), \n",
    "  tf.keras.metrics.Precision(name='precision', dtype=tf.float32),\n",
    "  tf.keras.metrics.Recall(name='recall', dtype=tf.float32),\n",
    "  tf.keras.metrics.AUC(name='auc', dtype=tf.float32),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_basic_block_layer(filter_num, blocks, stride=1):\n",
    "  \"\"\"\n",
    "  Generate a block layer\n",
    "  \"\"\"\n",
    "  res_block = tf.keras.Sequential()\n",
    "  res_block.add(basic_block(filter_num, stride=stride))\n",
    "\n",
    "  for _ in range(1, blocks):\n",
    "    res_block.add(basic_block(filter_num, stride=1))\n",
    "\n",
    "  return res_block\n",
    "\n",
    "def basic_block(filter_num, stride=1):\n",
    "  \"\"\"\n",
    "  Add a downsample layer depending on the  stride\n",
    "  \"\"\"\n",
    "  model  = tf.keras.Sequential([\n",
    "    layers.Conv2D(filters=filter_num, kernel_size=(3, 3), strides=stride, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=filter_num, kernel_size=(3, 3), strides=1, padding='same'),\n",
    "    layers.BatchNormalization()\n",
    "  ])\n",
    "\n",
    "  if stride != 1:\n",
    "    return tf.keras.Sequential([\n",
    "      model,\n",
    "      layers.Conv2D(filters=filter_num, kernel_size=(1, 1), strides=stride),\n",
    "      layers.BatchNormalization(),\n",
    "      layers.ReLU()\n",
    "    ])\n",
    "  else:\n",
    "    return model\n",
    "\n",
    "def make_bottleneck_layer(filter_num, blocks, stride=1):\n",
    "  \"\"\"\n",
    "  Generate a bottleneck layer\n",
    "  \"\"\"\n",
    "  res_block = tf.keras.Sequential()\n",
    "  res_block.add(bottleneck_layer(filter_num, stride=stride))\n",
    "\n",
    "  for _ in range(1, blocks):\n",
    "    res_block.add(bottleneck_layer(filter_num, stride=1))\n",
    "\n",
    "  return res_block\n",
    "\n",
    "def bottleneck_layer(filter_num, stride=1):\n",
    "  \"\"\"\n",
    "  Add a downsample layer\n",
    "  \"\"\"\n",
    "  model  = tf.keras.Sequential([\n",
    "    layers.Conv2D(filters=filter_num, kernel_size=(1, 1), strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=filter_num, kernel_size=(3, 3), strides=stride, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=filter_num * 4, kernel_size=(1, 1), strides=1, padding='same'),\n",
    "    layers.BatchNormalization()\n",
    "  ])\n",
    "\n",
    "  return tf.keras.Sequential([\n",
    "    model,\n",
    "    layers.Conv2D(filters=filter_num * 4, kernel_size=(1, 1), strides=stride),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU()\n",
    "  ])\n",
    "\n",
    "def resnet_18(final_activation):\n",
    "  nodes = [2, 2, 2, 2]\n",
    "  model = tf.keras.Sequential([\n",
    "      layers.Conv2D(16, 3, padding='same', input_shape=(IMG_HEIGHT, IMG_WIDTH , 3), strides=2),\n",
    "      layers.BatchNormalization(),\n",
    "      layers.ReLU(),\n",
    "      layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding='same'),\n",
    "      make_basic_block_layer(filter_num=64, blocks=nodes[0]),\n",
    "      make_basic_block_layer(filter_num=128, blocks=nodes[1], stride=2),\n",
    "      make_basic_block_layer(filter_num=256, blocks=nodes[2], stride=2),\n",
    "      make_basic_block_layer(filter_num=512, blocks=nodes[3], stride=2),\n",
    "      layers.GlobalAveragePooling2D(),\n",
    "      # layers.Dropout(0.1),\n",
    "      layers.Dense(units=NUM_CLASSES, activation=final_activation, name='predictions')\n",
    "  ])\n",
    "\n",
    "  return model\n",
    "\n",
    "def resnet_34(final_activation):\n",
    "  nodes = [3, 4, 6, 3]\n",
    "  model = tf.keras.Sequential([\n",
    "    layers.Conv2D(16, 3, padding='same', input_shape=(IMG_HEIGHT, IMG_WIDTH , 3), strides=2),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding='same'),\n",
    "    make_bottleneck_layer(filter_num=64, blocks=nodes[0]),\n",
    "    make_bottleneck_layer(filter_num=128, blocks=nodes[1], stride=2),\n",
    "    make_bottleneck_layer(filter_num=256, blocks=nodes[2], stride=2),\n",
    "    make_bottleneck_layer(filter_num=512, blocks=nodes[3], stride=2),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    # layers.Dropout(0.1),\n",
    "    layers.Dense(units=NUM_CLASSES, activation=final_activation, name='predictions')\n",
    "  ])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_vgg_16(nodes=16, optimizer='adam', loss='binary_crossentropy', hidden_activation='linear', final_activation='softmax', metrics='accuracy'):\n",
    "  \"\"\"\n",
    "  Return a VGG16 model - CF https://arxiv.org/pdf/1409.1556/\n",
    "  \"\"\"\n",
    "  model = tf.keras.Sequential([\n",
    "    layers.Conv2D(16, 3, padding='same', activation=hidden_activation, input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Conv2D(32, 3, padding='same', activation=hidden_activation),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Conv2D(64, 3, padding='same', activation=hidden_activation),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation=final_activation),\n",
    "    layers.Dense(units=NUM_CLASSES)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer=optimizer,\n",
    "                loss=loss,\n",
    "                metrics=metrics)\n",
    "  return model\n",
    "\n",
    "# vgg16 or resnet18 or resnet34\n",
    "MODEL_NAME = 'vgg16'\n",
    "\n",
    "model = get_model_vgg_16(\n",
    "        nodes=16,\n",
    "        optimizer=OPTIMIZER,\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        hidden_activation=HIDDEN_ACTIVATION,\n",
    "        final_activation=FINAL_ACTIVATION,\n",
    "        metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy', dtype=tf.float32)]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_resnet_18(optimizer='adam', loss='binary_crossentropy', final_activation='softmax', metrics='accuracy'):\n",
    "  \"\"\"\n",
    "  Return a resnet 18 model\n",
    "  \"\"\"\n",
    "  model = resnet_18(final_activation=final_activation)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss=loss,\n",
    "                metrics=metrics)\n",
    "    return model\n",
    "\n",
    "    model = resnet_34(final_activation=final_activation)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss=loss,\n",
    "                metrics=metrics)\n",
    "    return model\n",
    "\n",
    "# vgg16 or resnet18 or resnet34\n",
    "MODEL_NAME = 'resnet18'\n",
    "\n",
    "model = get_model_resnet_18(\n",
    "        optimizer=OPTIMIZER,\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        final_activation=FINAL_ACTIVATION,\n",
    "        metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy', dtype=tf.float32)]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_resnet_34(optimizer='adam', loss='binary_crossentropy', final_activation='softmax', metrics='accuracy'):\n",
    "  \"\"\"\n",
    "  Return a resnet 34 model\n",
    "  \"\"\"\n",
    "  model = resnet_34(final_activation=final_activation)\n",
    "  model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "  return model\n",
    "\n",
    "# vgg16 or resnet18 or resnet34\n",
    "MODEL_NAME = 'resnet34'\n",
    "\n",
    "model = get_model_resnet_34(\n",
    "        optimizer=OPTIMIZER,\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        final_activation=FINAL_ACTIVATION,\n",
    "        metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy', dtype=tf.float32)]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_h5(model=None, model_name='vgg16'):\n",
    "  \"\"\"\n",
    "  Save a TF Model into h5 format\n",
    "  \"\"\"\n",
    "  model.save('saved_model/{}/model.h5'.format(MODEL_NAME))\n",
    "  print(\"Model saved successfully.\")\n",
    "\n",
    "def save_model_tf(model=None, model_name='vgg16'):\n",
    "  \"\"\"\n",
    "  Save a TF Model into SavedModel format\n",
    "  \"\"\"\n",
    "  # Reset metrics before saving so that loaded model has same state,\n",
    "  # since metric states are not preserved by Model.save_weights\n",
    "  model.reset_metrics()\n",
    "\n",
    "  model.save('saved_model/{}/model'.format(MODEL_NAME), save_format='tf')\n",
    "  print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks():\n",
    "  \"\"\"\n",
    "  Define the callbacks for the ML model\n",
    "  \"\"\"\n",
    "  return [\n",
    "    # tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10),\n",
    "    tf.keras.callbacks.TensorBoard(os.path.join(\"logs/{}\".format(MODEL_NAME), datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")), histogram_freq=1)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  \"\"\"\n",
    "  Get the label of a file - Can be NORMAL, VIRUS OR BACTERIE\n",
    "  \"\"\"\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  return parts[-2] == CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "  \"\"\"\n",
    "  Convert an image into a tensor with needed size\n",
    "  \"\"\"\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "  \"\"\"\n",
    "  Process a file\n",
    "  \"\"\"\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_predicted(predictions):\n",
    "  \"\"\"\n",
    "  Return the label for a given prediction array\n",
    "  \"\"\"\n",
    "  preds = list(predictions)\n",
    "  return CLASS_NAMES[preds.index(max(preds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results(history, model, results, predictions):\n",
    "  \"\"\"\n",
    "  Function that generate an html page and open it in the browser\n",
    "  - history is the history for the model train steps\n",
    "  - results is the metrics results get from the train step\n",
    "  - predictions is the predictive result gotten for the test datas\n",
    "  \"\"\"\n",
    "  folder_results_name = 'results/{}_{}'.format(MODEL_NAME, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "  os.mkdir(folder_results_name, 0o755)\n",
    "\n",
    "  # Generate the graph for accuracy, loss, val_accuracy, val_loss\n",
    "  history_dict = history.history\n",
    "\n",
    "  acc = history_dict['accuracy']\n",
    "  val_acc = history_dict['val_accuracy']\n",
    "  loss = history_dict['loss']\n",
    "  val_loss = history_dict['val_loss']\n",
    "\n",
    "  epochs_range = range(NB_EPOCHS)\n",
    "\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "  plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.title('Training and Validation Accuracy')\n",
    "\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.plot(epochs_range, loss, label='Training Loss')\n",
    "  plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "  plt.legend(loc='upper right')\n",
    "  plt.title('Training and Validation Loss')\n",
    "  plt.yscale('log')\n",
    "\n",
    "  # save figure\n",
    "  plt.savefig('{}/accuracy_and_loss.png'.format(folder_results_name))\n",
    "\t# close matplotlib\n",
    "  plt.close()\n",
    "\n",
    "  with open('{}/results.txt'.format(folder_results_name), 'w+', newline='') as f:\n",
    "    # Write metrics for testing purpose\n",
    "    f.write('Normal, Virus or Bacteria {} trained model\\n'.format(MODEL_NAME))\n",
    "    if MODEL_NAME == 'vgg16':\n",
    "      f.write('Optimizer : {}, Hidden activation : {}, Final activation : {}\\n'.format(OPTIMIZER, HIDDEN_ACTIVATION, FINAL_ACTIVATION))\n",
    "    elif MODEL_NAME == 'resnet18' or MODEL_NAME == 'resnet34':\n",
    "      f.write('Optimizer : {}, Final activation : {}\\n'.format(OPTIMIZER, FINAL_ACTIVATION))\n",
    "    f.write('--------------------------------------------------------------\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('METRICS :\\n')\n",
    "    for name, value in zip(model.metrics_names, results):\n",
    "      f.write(f'{name} : {value}\\n')\n",
    "    f.write('\\n')\n",
    "    # Write predictions\n",
    "    f.write('PREDICTIONS :\\n')\n",
    "    for predict in predictions:\n",
    "      f.write('Predictions : {}, Result : {}\\n'.format(str(predict), get_label_predicted(predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the nb of steps and how many images we got\n",
    "nb_normal_tr = len(os.listdir('{}/NORMAL'.format(TRAIN_DATA_PATH)))\n",
    "nb_bacteria_tr = len(os.listdir('{}/BACTERIA'.format(TRAIN_DATA_PATH)))\n",
    "nb_virus_tr = len(os.listdir('{}/VIRUS'.format(TRAIN_DATA_PATH)))\n",
    "nb_normal_val = len(os.listdir('{}/NORMAL'.format(VAL_DATA_PATH)))\n",
    "nb_bacteria_val = len(os.listdir('{}/BACTERIA'.format(VAL_DATA_PATH)))\n",
    "nb_virus_val = len(os.listdir('{}/VIRUS'.format(VAL_DATA_PATH)))\n",
    "total_train = nb_normal_tr + nb_bacteria_tr + nb_virus_tr\n",
    "total_val = nb_normal_val + nb_bacteria_val + nb_virus_val\n",
    "\n",
    "# Our datas generators\n",
    "train_image_generator = ImageDataGenerator(\n",
    "  rescale=1./255,\n",
    "  rotation_range=45,\n",
    "  width_shift_range=.15,\n",
    "  height_shift_range=.15,\n",
    "  horizontal_flip=True,\n",
    "  zoom_range=0.5\n",
    ") # Generator for our training data\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data\n",
    "test_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "  directory=TRAIN_DATA_PATH,\n",
    "  shuffle=True,\n",
    "  target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  class_mode='categorical'\n",
    ")\n",
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "  directory=VAL_DATA_PATH,\n",
    "  target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  class_mode='categorical'\n",
    ")\n",
    "test_data_gen = test_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "  directory=TEST_DATA_PATH,\n",
    "  target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "  train_data_gen,\n",
    "  callbacks=get_callbacks(),\n",
    "  steps_per_epoch=total_train // BATCH_SIZE,\n",
    "  epochs=NB_EPOCHS,\n",
    "  validation_data=val_data_gen,\n",
    "  validation_steps=total_val // BATCH_SIZE\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Use a testing model to display metrics\n",
    "testing_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "testing_model.compile(\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "  optimizer='adam',\n",
    "  metrics=METRICS\n",
    ")\n",
    "\n",
    "# Evalutate the model with test datas\n",
    "results = testing_model.evaluate(test_data_gen, verbose=0)\n",
    "\n",
    "# Predict the test datas\n",
    "predictions = testing_model.predict(test_data_gen)\n",
    "\n",
    "generate_results(history, testing_model, results, predictions)\n",
    "# save_model_h5(testing_model, 'resnet_18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
